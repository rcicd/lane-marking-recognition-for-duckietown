{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a655e0d0c36eef",
   "metadata": {},
   "source": [
    "# Notebook that used for training\n",
    "Training was performed in google colab on A100 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca70f3e33a5a2d5",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ead246c93b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "import random\n",
    "from typing import List\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2a5f0acbd48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spot(image: np.ndarray, seg_mask: np.ndarray, probability=0.5, alpha=0.6) -> np.ndarray:\n",
    "    image_ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    Y_channel = image_ycrcb[:,:,0]\n",
    "\n",
    "    yellow_color = np.array([255, 255, 0])\n",
    "    mask_yellow_seg = cv2.inRange(seg_mask, yellow_color, yellow_color)\n",
    "\n",
    "    brightness_mask = np.uint8((Y_channel > 100) * 255)\n",
    "\n",
    "    valid_yellow_mask = cv2.bitwise_and(mask_yellow_seg, brightness_mask)\n",
    "\n",
    "    red_color = np.array([255, 0, 0])\n",
    "    mask_red_seg = cv2.inRange(seg_mask, red_color, red_color)\n",
    "\n",
    "    contours_yellow, _ = cv2.findContours(valid_yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_red, _ = cv2.findContours(mask_red_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    for cnt in contours_yellow:\n",
    "        if random.random() < probability:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            radius = (min(w, h)) // 2\n",
    "            cv2.circle(overlay, center, radius, (255, 255, 255), -1)\n",
    "\n",
    "    for cnt in contours_red:\n",
    "        if random.random() < probability:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            radius = (max(w, h)) // 3\n",
    "            cv2.circle(overlay, center, radius, (255, 255, 255), -1)\n",
    "\n",
    "    overlay = cv2.GaussianBlur(overlay, (0, 0), sigmaX=5, sigmaY=5)\n",
    "    combined_mask = cv2.bitwise_or(mask_yellow_seg, mask_red_seg)\n",
    "    combined_mask_3ch = cv2.merge([combined_mask, combined_mask, combined_mask])\n",
    "    overlay = cv2.bitwise_and(overlay, combined_mask_3ch)\n",
    "    result = cv2.addWeighted(image, 1, overlay, alpha, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a7264f25d58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadMarkupsDataset(Dataset):\n",
    "    def __init__(self, root_dirs: List[str], mask_dirs: List[str], mode: str, custom_transforms=None, custom_transform_p=0.5, transform=None, seed=42):\n",
    "        self.root_dir = root_dirs\n",
    "        self.transform: A.Compose = transform\n",
    "        self.mode = mode\n",
    "        self.images: List[np.ndarray] = []\n",
    "        self.custom_transform_p = custom_transform_p\n",
    "        self.custom_transforms = custom_transforms\n",
    "        self.masks = []\n",
    "        self.names_buffer = [os.listdir(dir) for dir in root_dirs]\n",
    "        self.names = sorted([os.path.join(root_dirs[i], self.names_buffer[i][j]) for i in range(len(root_dirs)) for j in range(len(self.names_buffer[i]))])\n",
    "        self.mask_names_buffer = [os.listdir(dir) for dir in mask_dirs]\n",
    "        self.mask_names = sorted([os.path.join(mask_dirs[i], self.mask_names_buffer[i][j]) for i in range(len(mask_dirs)) for j in range(len(self.mask_names_buffer[i]))])\n",
    "        if mode == 'train':\n",
    "            random.seed(seed)\n",
    "            indices = list(range(len(self.names)))\n",
    "            random.shuffle(indices)\n",
    "            self.names = [self.names[i] for i in indices]\n",
    "            self.mask_names = [self.mask_names[i] for i in indices]\n",
    "        if mode != 'train' and mode != 'valid' and mode != 'test':\n",
    "            raise ValueError(f'Unknown mode: {mode}')\n",
    "        self.images = [cv2.cvtColor(cv2.imread(self.names[idx]), cv2.COLOR_BGR2RGB)[-160:,:,:] for idx in tqdm(range(len(self.names)))]\n",
    "        self.masks = [cv2.cvtColor(cv2.imread(self.mask_names[idx]), cv2.COLOR_BGR2RGB)[-160:,:,:] for idx in tqdm(range(len(self.mask_names)))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        if self.custom_transforms:\n",
    "            if random.random() < self.custom_transform_p:\n",
    "                image, mask = self.custom_transforms(image, mask)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        tensor_image = torch.from_numpy(image).float().permute(2, 0, 1) / 255\n",
    "        mask_buffer = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int64)\n",
    "        mask_buffer[np.all(mask == [255, 255, 255], axis=-1)] = 1\n",
    "        mask_buffer[np.all(mask == [255, 255, 0], axis=-1)] = 2\n",
    "        mask_buffer[np.all(mask == [255, 0, 0], axis=-1)] = 3\n",
    "        tensor_mask = torch.from_numpy(mask_buffer)\n",
    "\n",
    "        return tensor_image, tensor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93628e11f5a69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicMobileNetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, leaky_relu_coef=0, dropout=0.3, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.spatial_convolve = torch.nn.Conv2d(\n",
    "            in_dim,\n",
    "            in_dim,\n",
    "            kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            padding_mode=\"zeros\",\n",
    "            groups=in_dim,\n",
    "        )\n",
    "        self.depthwise_convolve = torch.nn.Conv2d(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        if leaky_relu_coef == 0:\n",
    "            self.ReLU = torch.nn.ReLU()\n",
    "        else:\n",
    "            self.ReLU = torch.nn.LeakyReLU(leaky_relu_coef)\n",
    "        self.batch_norm = torch.nn.BatchNorm2d(out_dim)\n",
    "        self.dropout = torch.nn.Dropout2d(p=dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        _X = self.spatial_convolve(X)\n",
    "        _X = self.depthwise_convolve(X)\n",
    "        _X = self.batch_norm(_X)\n",
    "        _X = self.ReLU(_X)\n",
    "        return self.dropout(_X)\n",
    "\n",
    "class MySegmentationNet(torch.nn.Module):\n",
    "    def __init__(self, block_amount=2, leaky_relu_coef=0, dropout=0.3, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.in_layer = BasicMobileNetBlock(3, 64, leaky_relu_coef=0, dropout=0.3, kernel_size=3)\n",
    "        self.basic_layers = torch.nn.Sequential()\n",
    "        for i in range(block_amount):\n",
    "            self.basic_layers.append(BasicMobileNetBlock(64, 64, leaky_relu_coef=0, dropout=0.3, kernel_size=3))\n",
    "        self.out_layer = torch.nn.Conv2d(64, 4, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        _X = self.in_layer(X)\n",
    "        _X = self.basic_layers(_X)\n",
    "        return self.out_layer(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2968b1859193cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall(torch.nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        gt_positive = gt == self.target\n",
    "        TP = (pred[gt_positive] == self.target).sum()\n",
    "        FN = (~(pred[gt_positive] == self.target)).sum()\n",
    "        return (TP + 1) / (TP + FN + 1)\n",
    "\n",
    "\n",
    "class Precision(torch.nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        gt_positive = gt == self.target\n",
    "        TP = (pred[gt_positive] == self.target).sum()\n",
    "        FP = (pred[~gt_positive] == self.target).sum()\n",
    "        return (TP + 1) / (TP + FP + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a437eae15a8c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "class Trainer(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            opt='adam',\n",
    "            red_weight=5.0,\n",
    "            white_weight=5.0,\n",
    "            yellow_weight=5.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.opt = opt\n",
    "\n",
    "        self.model = model\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, white_weight, yellow_weight, red_weight]))\n",
    "        self.val_recal_red = Recall(3)\n",
    "        self.val_precision_red = Precision(3)\n",
    "        self.val_recal_yellow = Recall(2)\n",
    "        self.val_precision_yellow = Precision(2)\n",
    "        self.val_recal_white = Recall(1)\n",
    "        self.val_precision_white = Precision(1)\n",
    "        self.is_first = True\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"The full training loop\"\"\"\n",
    "        if self.is_first:\n",
    "            print(\"Starting training...\")\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        metrics = {\"train_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        if self.is_first:\n",
    "            print(\"First itteration finished\")\n",
    "            self.is_first = False\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Define optimizers and LR schedulers.\"\"\"\n",
    "        if self.opt == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=True,\n",
    "        )\n",
    "        lr_dict = {\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "        return [optimizer], [lr_dict]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"the full validation loop\"\"\"\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        # print(y_pred)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "        y_label = y\n",
    "\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        red_recal = self.val_recal_red(y_label, y_pred_label)\n",
    "        red_precision = self.val_precision_red(y_label, y_pred_label)\n",
    "        yellow_recal = self.val_recal_yellow(y_label, y_pred_label)\n",
    "        yellow_precision = self.val_precision_yellow(y_label, y_pred_label)\n",
    "        white_recal = self.val_recal_white(y_label, y_pred_label)\n",
    "        white_precision = self.val_precision_white(y_label, y_pred_label)\n",
    "\n",
    "        metrics = {\n",
    "            \"val_loss\": loss,\n",
    "            \"red_recal\": red_recal,\n",
    "            \"red_precision\": red_precision,\n",
    "            \"yellow_recal\": yellow_recal,\n",
    "            \"yellow_precision\": yellow_precision,\n",
    "            \"white_recal\" : white_recal,\n",
    "            \"white_precision\" : white_precision,\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e87d5bed3cbf",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2ac783790871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Change paths\n",
    "train_data_dirs = [\"/path/to/train/data/dir\"]\n",
    "train_mask_dirs = [\"/path/to/train/masks/dir\"]\n",
    "\n",
    "valid_data_dirs = [\"/path/to/valid/data/dir\"]\n",
    "valid_mask_dirs = [\"/path/to/valid/masks/dir\"]\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Compose([\n",
    "            A.HorizontalFlip(p=.5),\n",
    "        ]),\n",
    "        A.OneOf([\n",
    "            A.RGBShift(\n",
    "                r_shift_limit=(-50, 50),\n",
    "                b_shift_limit=(-50, 50),\n",
    "                g_shift_limit=(-50, 50),\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=(-20, 20),\n",
    "                sat_shift_limit=(-50, 50),\n",
    "                val_shift_limit=(-50, 50),\n",
    "                p=1.0\n",
    "            )\n",
    "        ], p=.5),\n",
    "        A.RandomGravel(gravel_roi=(0.1, 0.1, 0.9, 0.9), number_of_patches=5, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomGamma(p=1.0, gamma_limit=(199, 200)),\n",
    "            A.RandomShadow(shadow_roi=(0.2, 0.2, 0.8, 0.8), num_shadows_limit=(3, 5), shadow_dimension=7, shadow_intensity_range=(0.1, 0.3), p=1.0)\n",
    "        ], p=.5),\n",
    "        A.RandomFog(alpha_coef=0.9, fog_coef_range=(0.1, 0.2), p=.5),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def custom_transforms(image, mask):\n",
    "    image = add_spot(image, mask, probability=0.3, alpha=0.6)\n",
    "    return image, mask\n",
    "\n",
    "ds_train = RoadMarkupsDataset(train_data_dirs, train_mask_dirs, \"train\", transform=transforms, custom_transforms=custom_transforms)\n",
    "ds_val = RoadMarkupsDataset(valid_data_dirs, valid_mask_dirs, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99584fc3e9a33c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd71c49a6acbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyNetCheckpoint = ModelCheckpoint(\n",
    "    dirpath=\"/path/to/checkpoints/\", # TODO Change path\n",
    "    filename=\"{epoch}-{val_loss:.3f}\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    "    monitor=\"val_loss\",\n",
    "    every_n_epochs=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "MyEarlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45d875037b0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666ccc6fb816988",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[MyEarlyStopping, MyNetCheckpoint],\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "training_module = Trainer(\n",
    "    model=MySegmentationNet(),\n",
    "    yellow_weight=7.0\n",
    ")\n",
    "\n",
    "trainer.fit(training_module, dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecff98c73b86528",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46e6c7d9b7994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracySum(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        return (gt == pred).sum()\n",
    "\n",
    "class Accuracy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        return (gt == pred).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d589ff4b8915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_truth_matrix(target, gt, pred):\n",
    "    gt_positive = gt == target\n",
    "    TP = (pred[gt_positive] == target).sum()\n",
    "    FP = (pred[~gt_positive] == target).sum()\n",
    "    FN = (~(pred[gt_positive] == target)).sum()\n",
    "    return TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc8b35335349df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = [\"/path/to/test/data/dir\"] # TODO Change path\n",
    "mask_dirs = [\"/path/to/test/masks/dir\"] # TODO Change path\n",
    "ds_test = RoadMarkupsDataset(test_dirs, mask_dirs, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e8ab58668596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "def testing(model, dataset, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dl_test = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())\n",
    "    recal_red = Recall(3)\n",
    "    precision_red = Precision(3)\n",
    "    recal_yellow = Recall(2)\n",
    "    precision_yellow = Precision(2)\n",
    "    recal_white = Recall(1)\n",
    "    precision_white = Precision(1)\n",
    "    accuracy_func = Accuracy()\n",
    "    accuracy_sum = AccuracySum()\n",
    "    metrics = {\n",
    "        \"accuracy\": 0,\n",
    "        \"red_recal\": 0,\n",
    "        \"red_precision\": 0,\n",
    "        \"yellow_recal\": 0,\n",
    "        \"yellow_precision\": 0,\n",
    "        \"white_recal\" : 0,\n",
    "        \"white_precision\" : 0,\n",
    "    }\n",
    "    rTP, rFP, rFN = 0.0, 0.0, 0.0\n",
    "    yTP, yFP, yFN = 0.0, 0.0, 0.0\n",
    "    wTP, wFP, wFN = 0.0, 0.0, 0.0\n",
    "\n",
    "    recal_red_mean_per_picture = 0.0\n",
    "    precision_red_mean_per_picture = 0.0\n",
    "    recal_yellow_mean_per_picture = 0.0\n",
    "    precision_yellow_mean_per_picture = 0.0\n",
    "    recal_white_mean_per_picture = 0.0\n",
    "    precision_white_mean_per_picture = 0.0\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    accuracy_mean_per_picture = 0.0\n",
    "\n",
    "    pictures_amount = 0\n",
    "    time_delta = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl_test):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            pictures_amount += y.size()[0]\n",
    "            time_start = time.time_ns()\n",
    "            y_pred_gpu = model(x)\n",
    "            time_end = time.time_ns()\n",
    "            time_delta += time_end - time_start\n",
    "            y_pred = y_pred_gpu.to(torch.device(\"cpu\"))\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            _rTP, _rFP, _rFN = calculate_truth_matrix(3, y, y_pred_label)\n",
    "            _yTP, _yFP, _yFN = calculate_truth_matrix(2, y, y_pred_label)\n",
    "            _wTP, _wFP, _wFN = calculate_truth_matrix(1, y, y_pred_label)\n",
    "            rTP += _rTP\n",
    "            rFP +=_rFP\n",
    "            rFN +=_rFN\n",
    "            yTP += _yTP\n",
    "            yFP +=_yFP\n",
    "            yFN +=_yFN\n",
    "            wTP += _wTP\n",
    "            wFP +=_wFP\n",
    "            wFN +=_wFN\n",
    "\n",
    "            accuracy += accuracy_sum(y, y_pred_label)\n",
    "\n",
    "            recal_red_mean_per_picture += value if not np.isnan(value := recal_red(y, y_pred_label).item()) else 1.0\n",
    "            precision_red_mean_per_picture += value if not np.isnan(value := precision_red(y, y_pred_label).item()) else 1.0\n",
    "            recal_yellow_mean_per_picture += value if not np.isnan(value := recal_yellow(y, y_pred_label).item()) else 1.0\n",
    "            precision_yellow_mean_per_picture += value if not np.isnan(value := precision_yellow(y, y_pred_label).item()) else 1.0\n",
    "            recal_white_mean_per_picture += value if not np.isnan(value := recal_white(y, y_pred_label).item()) else 1.0\n",
    "            precision_white_mean_per_picture += value if not np.isnan(value := precision_white(y, y_pred_label).item()) else 1.0\n",
    "            accuracy_mean_per_picture += accuracy_func(y, y_pred_label)\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "            del y_pred_label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy / (pictures_amount * 640 * 160),\n",
    "        \"red_recal\": rTP / (rTP + rFN),\n",
    "        \"red_precision\": rTP / (rTP + rFP),\n",
    "        \"yellow_recal\": yTP / (yTP + yFN),\n",
    "        \"yellow_precision\": yTP / (yTP + yFP),\n",
    "        \"white_recal\" : wTP / (wTP + wFN),\n",
    "        \"white_precision\" : wTP / (wTP + wFP),\n",
    "\n",
    "        \"accuracy_mean_per_picture\": accuracy_mean_per_picture / pictures_amount,\n",
    "        \"red_recal_mean_per_picture\": recal_red_mean_per_picture / pictures_amount,\n",
    "        \"red_precision_mean_per_picture\": precision_red_mean_per_picture / pictures_amount,\n",
    "        \"yellow_recal_mean_per_picture\": recal_yellow_mean_per_picture / pictures_amount,\n",
    "        \"yellow_precision_mean_per_picture\": precision_yellow_mean_per_picture / pictures_amount,\n",
    "        \"white_recal_mean_per_picture\" : recal_white_mean_per_picture / pictures_amount,\n",
    "        \"white_precision_mean_per_picture\" : precision_white_mean_per_picture / pictures_amount,\n",
    "        \"time_delta\": time_delta / pictures_amount,\n",
    "    }\n",
    "    del model\n",
    "    del dl_test\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84a4118d6f3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = testing(trainer.model, ds_test, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612514ab55e6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6d8652c1f354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"/path/to/model.pt\") # TODO Change path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

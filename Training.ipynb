{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a655e0d0c36eef",
   "metadata": {},
   "source": [
    "# Notebook that used for training\n",
    "Training was performed in google colab on A100 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca70f3e33a5a2d5",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ead246c93b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "import random\n",
    "from typing import List\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2a5f0acbd48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spot(image: np.ndarray, seg_mask: np.ndarray, probability=0.5, alpha=0.6) -> np.ndarray:\n",
    "    image_ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    Y_channel = image_ycrcb[:,:,0]\n",
    "\n",
    "    yellow_color = np.array([255, 255, 0])\n",
    "    mask_yellow_seg = cv2.inRange(seg_mask, yellow_color, yellow_color)\n",
    "\n",
    "    brightness_mask = np.uint8((Y_channel > 100) * 255)\n",
    "\n",
    "    valid_yellow_mask = cv2.bitwise_and(mask_yellow_seg, brightness_mask)\n",
    "\n",
    "    red_color = np.array([255, 0, 0])\n",
    "    mask_red_seg = cv2.inRange(seg_mask, red_color, red_color)\n",
    "\n",
    "    contours_yellow, _ = cv2.findContours(valid_yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_red, _ = cv2.findContours(mask_red_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    for cnt in contours_yellow:\n",
    "        if random.random() < probability:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            radius = (min(w, h)) // 2\n",
    "            cv2.circle(overlay, center, radius, (255, 255, 255), -1)\n",
    "\n",
    "    for cnt in contours_red:\n",
    "        if random.random() < probability:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            radius = (max(w, h)) // 3\n",
    "            cv2.circle(overlay, center, radius, (255, 255, 255), -1)\n",
    "\n",
    "    overlay = cv2.GaussianBlur(overlay, (0, 0), sigmaX=5, sigmaY=5)\n",
    "    combined_mask = cv2.bitwise_or(mask_yellow_seg, mask_red_seg)\n",
    "    combined_mask_3ch = cv2.merge([combined_mask, combined_mask, combined_mask])\n",
    "    overlay = cv2.bitwise_and(overlay, combined_mask_3ch)\n",
    "    result = cv2.addWeighted(image, 1, overlay, alpha, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a7264f25d58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadMarkupsDataset(Dataset):\n",
    "    def __init__(self, root_dirs: List[str], mask_dirs: List[str], mode: str, custom_transforms=None, custom_transform_p=0.5, transform=None, seed=42):\n",
    "        self.root_dir = root_dirs\n",
    "        self.transform: A.Compose = transform\n",
    "        self.mode = mode\n",
    "        self.images: List[np.ndarray] = []\n",
    "        self.custom_transform_p = custom_transform_p\n",
    "        self.custom_transforms = custom_transforms\n",
    "        self.masks = []\n",
    "        self.names_buffer = [os.listdir(dir) for dir in root_dirs]\n",
    "        self.names = sorted([os.path.join(root_dirs[i], self.names_buffer[i][j]) for i in range(len(root_dirs)) for j in range(len(self.names_buffer[i]))])\n",
    "        self.mask_names_buffer = [os.listdir(dir) for dir in mask_dirs]\n",
    "        self.mask_names = sorted([os.path.join(mask_dirs[i], self.mask_names_buffer[i][j]) for i in range(len(mask_dirs)) for j in range(len(self.mask_names_buffer[i]))])\n",
    "        if mode == 'train':\n",
    "            random.seed(seed)\n",
    "            indices = list(range(len(self.names)))\n",
    "            random.shuffle(indices)\n",
    "            self.names = [self.names[i] for i in indices]\n",
    "            self.mask_names = [self.mask_names[i] for i in indices]\n",
    "        if mode != 'train' and mode != 'valid' and mode != 'test':\n",
    "            raise ValueError(f'Unknown mode: {mode}')\n",
    "        self.images = [cv2.cvtColor(cv2.imread(self.names[idx]), cv2.COLOR_BGR2RGB)[-160:,:,:] for idx in tqdm(range(len(self.names)))]\n",
    "        self.masks = [cv2.cvtColor(cv2.imread(self.mask_names[idx]), cv2.COLOR_BGR2RGB)[-160:,:,:] for idx in tqdm(range(len(self.mask_names)))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        if self.custom_transforms:\n",
    "            if random.random() < self.custom_transform_p:\n",
    "                image, mask = self.custom_transforms(image, mask)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        tensor_image = torch.from_numpy(image).float().permute(2, 0, 1) / 255\n",
    "        mask_buffer = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int64)\n",
    "        mask_buffer[np.all(mask == [255, 255, 255], axis=-1)] = 1\n",
    "        mask_buffer[np.all(mask == [255, 255, 0], axis=-1)] = 2\n",
    "        mask_buffer[np.all(mask == [255, 0, 0], axis=-1)] = 3\n",
    "        tensor_mask = torch.from_numpy(mask_buffer)\n",
    "\n",
    "        return tensor_image, tensor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93628e11f5a69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicMobileNetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, leaky_relu_coef=0, dropout=0.3, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.spatial_convolve = torch.nn.Conv2d(\n",
    "            in_dim,\n",
    "            in_dim,\n",
    "            kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            padding_mode=\"zeros\",\n",
    "            groups=in_dim,\n",
    "        )\n",
    "        self.depthwise_convolve = torch.nn.Conv2d(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        if leaky_relu_coef == 0:\n",
    "            self.ReLU = torch.nn.ReLU()\n",
    "        else:\n",
    "            self.ReLU = torch.nn.LeakyReLU(leaky_relu_coef)\n",
    "        self.batch_norm = torch.nn.BatchNorm2d(out_dim)\n",
    "        self.dropout = torch.nn.Dropout2d(p=dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        _X = self.spatial_convolve(X)\n",
    "        _X = self.depthwise_convolve(X)\n",
    "        _X = self.batch_norm(_X)\n",
    "        _X = self.ReLU(_X)\n",
    "        return self.dropout(_X)\n",
    "\n",
    "class MySegmentationNet(torch.nn.Module):\n",
    "    def __init__(self, block_amount=2, leaky_relu_coef=0, dropout=0.3, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.in_layer = BasicMobileNetBlock(3, 64, leaky_relu_coef=0, dropout=0.3, kernel_size=3)\n",
    "        self.basic_layers = torch.nn.Sequential()\n",
    "        for i in range(block_amount):\n",
    "            self.basic_layers.append(BasicMobileNetBlock(64, 64, leaky_relu_coef=0, dropout=0.3, kernel_size=3))\n",
    "        self.out_layer = torch.nn.Conv2d(64, 4, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        _X = self.in_layer(X)\n",
    "        _X = self.basic_layers(_X)\n",
    "        return self.out_layer(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2968b1859193cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall(torch.nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        gt_positive = gt == self.target\n",
    "        TP = (pred[gt_positive] == self.target).sum()\n",
    "        FN = (~(pred[gt_positive] == self.target)).sum()\n",
    "        return (TP + 1) / (TP + FN + 1)\n",
    "\n",
    "\n",
    "class Precision(torch.nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        gt_positive = gt == self.target\n",
    "        TP = (pred[gt_positive] == self.target).sum()\n",
    "        FP = (pred[~gt_positive] == self.target).sum()\n",
    "        return (TP + 1) / (TP + FP + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a437eae15a8c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "class Trainer(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            opt='adam',\n",
    "            red_weight=5.0,\n",
    "            white_weight=5.0,\n",
    "            yellow_weight=5.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.opt = opt\n",
    "\n",
    "        self.model = model\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, white_weight, yellow_weight, red_weight]))\n",
    "        self.val_recal_red = Recall(3)\n",
    "        self.val_precision_red = Precision(3)\n",
    "        self.val_recal_yellow = Recall(2)\n",
    "        self.val_precision_yellow = Precision(2)\n",
    "        self.val_recal_white = Recall(1)\n",
    "        self.val_precision_white = Precision(1)\n",
    "        self.is_first = True\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"The full training loop\"\"\"\n",
    "        if self.is_first:\n",
    "            print(\"Starting training...\")\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        metrics = {\"train_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        if self.is_first:\n",
    "            print(\"First itteration finished\")\n",
    "            self.is_first = False\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Define optimizers and LR schedulers.\"\"\"\n",
    "        if self.opt == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=True,\n",
    "        )\n",
    "        lr_dict = {\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "        return [optimizer], [lr_dict]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"the full validation loop\"\"\"\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        # print(y_pred)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "        y_label = y\n",
    "\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        red_recal = self.val_recal_red(y_label, y_pred_label)\n",
    "        red_precision = self.val_precision_red(y_label, y_pred_label)\n",
    "        yellow_recal = self.val_recal_yellow(y_label, y_pred_label)\n",
    "        yellow_precision = self.val_precision_yellow(y_label, y_pred_label)\n",
    "        white_recal = self.val_recal_white(y_label, y_pred_label)\n",
    "        white_precision = self.val_precision_white(y_label, y_pred_label)\n",
    "\n",
    "        metrics = {\n",
    "            \"val_loss\": loss,\n",
    "            \"red_recal\": red_recal,\n",
    "            \"red_precision\": red_precision,\n",
    "            \"yellow_recal\": yellow_recal,\n",
    "            \"yellow_precision\": yellow_precision,\n",
    "            \"white_recal\" : white_recal,\n",
    "            \"white_precision\" : white_precision,\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e87d5bed3cbf",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2ac783790871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Change paths\n",
    "train_data_dirs = [\"/path/to/train/data/dir\"]\n",
    "train_mask_dirs = [\"/path/to/train/masks/dir\"]\n",
    "\n",
    "valid_data_dirs = [\"/path/to/valid/data/dir\"]\n",
    "valid_mask_dirs = [\"/path/to/valid/masks/dir\"]\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Compose([\n",
    "            A.HorizontalFlip(p=.5),\n",
    "        ]),\n",
    "        A.OneOf([\n",
    "            A.RGBShift(\n",
    "                r_shift_limit=(-50, 50),\n",
    "                b_shift_limit=(-50, 50),\n",
    "                g_shift_limit=(-50, 50),\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=(-20, 20),\n",
    "                sat_shift_limit=(-50, 50),\n",
    "                val_shift_limit=(-50, 50),\n",
    "                p=1.0\n",
    "            )\n",
    "        ], p=.5),\n",
    "        A.RandomGravel(gravel_roi=(0.1, 0.1, 0.9, 0.9), number_of_patches=5, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomGamma(p=1.0, gamma_limit=(199, 200)),\n",
    "            A.RandomShadow(shadow_roi=(0.2, 0.2, 0.8, 0.8), num_shadows_limit=(3, 5), shadow_dimension=7, shadow_intensity_range=(0.1, 0.3), p=1.0)\n",
    "        ], p=.5),\n",
    "        A.RandomFog(alpha_coef=0.9, fog_coef_range=(0.1, 0.2), p=.5),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def custom_transforms(image, mask):\n",
    "    image = add_spot(image, mask, probability=0.3, alpha=0.6)\n",
    "    return image, mask\n",
    "\n",
    "ds_train = RoadMarkupsDataset(train_data_dirs, train_mask_dirs, \"train\", transform=transforms, custom_transforms=custom_transforms)\n",
    "ds_val = RoadMarkupsDataset(valid_data_dirs, valid_mask_dirs, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99584fc3e9a33c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd71c49a6acbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyNetCheckpoint = ModelCheckpoint(\n",
    "    dirpath=\"/path/to/checkpoints/\", # TODO Change path\n",
    "    filename=\"{epoch}-{val_loss:.3f}\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    "    monitor=\"val_loss\",\n",
    "    every_n_epochs=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "MyEarlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45d875037b0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666ccc6fb816988",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[MyEarlyStopping, MyNetCheckpoint],\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "training_module = Trainer(\n",
    "    model=MySegmentationNet(),\n",
    "    yellow_weight=7.0\n",
    ")\n",
    "\n",
    "trainer.fit(training_module, dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecff98c73b86528",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46e6c7d9b7994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracySum(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        return (gt == pred).sum()\n",
    "\n",
    "class Accuracy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        return (gt == pred).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d589ff4b8915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_truth_matrix(target, gt, pred):\n",
    "    gt_positive = gt == target\n",
    "    TP = (pred[gt_positive] == target).sum()\n",
    "    FP = (pred[~gt_positive] == target).sum()\n",
    "    FN = (~(pred[gt_positive] == target)).sum()\n",
    "    return TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc8b35335349df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = [\"/path/to/test/data/dir\"] # TODO Change path\n",
    "mask_dirs = [\"/path/to/test/masks/dir\"] # TODO Change path\n",
    "ds_test = RoadMarkupsDataset(test_dirs, mask_dirs, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e8ab58668596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "def testing(model, dataset, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dl_test = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())\n",
    "    recal_red = Recall(3)\n",
    "    precision_red = Precision(3)\n",
    "    recal_yellow = Recall(2)\n",
    "    precision_yellow = Precision(2)\n",
    "    recal_white = Recall(1)\n",
    "    precision_white = Precision(1)\n",
    "    accuracy_func = Accuracy()\n",
    "    accuracy_sum = AccuracySum()\n",
    "    metrics = {\n",
    "        \"accuracy\": 0,\n",
    "        \"red_recal\": 0,\n",
    "        \"red_precision\": 0,\n",
    "        \"yellow_recal\": 0,\n",
    "        \"yellow_precision\": 0,\n",
    "        \"white_recal\" : 0,\n",
    "        \"white_precision\" : 0,\n",
    "    }\n",
    "    rTP, rFP, rFN = 0.0, 0.0, 0.0\n",
    "    yTP, yFP, yFN = 0.0, 0.0, 0.0\n",
    "    wTP, wFP, wFN = 0.0, 0.0, 0.0\n",
    "\n",
    "    recal_red_mean_per_picture = 0.0\n",
    "    precision_red_mean_per_picture = 0.0\n",
    "    recal_yellow_mean_per_picture = 0.0\n",
    "    precision_yellow_mean_per_picture = 0.0\n",
    "    recal_white_mean_per_picture = 0.0\n",
    "    precision_white_mean_per_picture = 0.0\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    accuracy_mean_per_picture = 0.0\n",
    "\n",
    "    pictures_amount = 0\n",
    "    time_delta = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl_test):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            pictures_amount += y.size()[0]\n",
    "            time_start = time.time_ns()\n",
    "            y_pred_gpu = model(x)\n",
    "            time_end = time.time_ns()\n",
    "            time_delta += time_end - time_start\n",
    "            y_pred = y_pred_gpu.to(torch.device(\"cpu\"))\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            _rTP, _rFP, _rFN = calculate_truth_matrix(3, y, y_pred_label)\n",
    "            _yTP, _yFP, _yFN = calculate_truth_matrix(2, y, y_pred_label)\n",
    "            _wTP, _wFP, _wFN = calculate_truth_matrix(1, y, y_pred_label)\n",
    "            rTP += _rTP\n",
    "            rFP +=_rFP\n",
    "            rFN +=_rFN\n",
    "            yTP += _yTP\n",
    "            yFP +=_yFP\n",
    "            yFN +=_yFN\n",
    "            wTP += _wTP\n",
    "            wFP +=_wFP\n",
    "            wFN +=_wFN\n",
    "\n",
    "            accuracy += accuracy_sum(y, y_pred_label)\n",
    "\n",
    "            recal_red_mean_per_picture += value if not np.isnan(value := recal_red(y, y_pred_label).item()) else 1.0\n",
    "            precision_red_mean_per_picture += value if not np.isnan(value := precision_red(y, y_pred_label).item()) else 1.0\n",
    "            recal_yellow_mean_per_picture += value if not np.isnan(value := recal_yellow(y, y_pred_label).item()) else 1.0\n",
    "            precision_yellow_mean_per_picture += value if not np.isnan(value := precision_yellow(y, y_pred_label).item()) else 1.0\n",
    "            recal_white_mean_per_picture += value if not np.isnan(value := recal_white(y, y_pred_label).item()) else 1.0\n",
    "            precision_white_mean_per_picture += value if not np.isnan(value := precision_white(y, y_pred_label).item()) else 1.0\n",
    "            accuracy_mean_per_picture += accuracy_func(y, y_pred_label)\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "            del y_pred_label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy / (pictures_amount * 640 * 160),\n",
    "        \"red_recal\": rTP / (rTP + rFN),\n",
    "        \"red_precision\": rTP / (rTP + rFP),\n",
    "        \"yellow_recal\": yTP / (yTP + yFN),\n",
    "        \"yellow_precision\": yTP / (yTP + yFP),\n",
    "        \"white_recal\" : wTP / (wTP + wFN),\n",
    "        \"white_precision\" : wTP / (wTP + wFP),\n",
    "\n",
    "        \"accuracy_mean_per_picture\": accuracy_mean_per_picture / pictures_amount,\n",
    "        \"red_recal_mean_per_picture\": recal_red_mean_per_picture / pictures_amount,\n",
    "        \"red_precision_mean_per_picture\": precision_red_mean_per_picture / pictures_amount,\n",
    "        \"yellow_recal_mean_per_picture\": recal_yellow_mean_per_picture / pictures_amount,\n",
    "        \"yellow_precision_mean_per_picture\": precision_yellow_mean_per_picture / pictures_amount,\n",
    "        \"white_recal_mean_per_picture\" : recal_white_mean_per_picture / pictures_amount,\n",
    "        \"white_precision_mean_per_picture\" : precision_white_mean_per_picture / pictures_amount,\n",
    "        \"time_delta\": time_delta / pictures_amount,\n",
    "    }\n",
    "    del model\n",
    "    del dl_test\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84a4118d6f3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = testing(trainer.model, ds_test, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612514ab55e6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6d8652c1f354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"/path/to/model.pt\") # TODO Change path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a2ff832b593a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ilia.Nechaev/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097e1fe7-02a0-408e-83ab-e5334daa03ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7e22a41eb7c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(\"out.png\", cv2.IMREAD_UNCHANGED)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ead218-5108-4b24-a56c-a18a1c7341a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae3af1-ce1e-4254-a7cd-41d863ac1f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
